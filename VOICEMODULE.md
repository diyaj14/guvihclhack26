# ðŸŽ™ï¸ Phase 3: The Voice Module (Vigilante Voice Core)

## 1. Introduction & Concept
This module is the "Voice" of the Vigilante AI system. Unlike a chatbot that waits for you to hit "Send," a voice agent must handle **continuous, bidirectional audio streams**. It needs to "listen" while "speaking" (full-duplex) and handle interruptions naturally.

**The Goal**: Create an AI that sounds like a confused grandmother (or other persona) that can hold a conversation with a scammer in real-time (sub-500ms latency).

## 2. The Physics of Real-Time Voice AI
To trick a human, the AI must respond faster than the human brain perceives a delay.

### The "Latency Budget"
A natural conversation gap is **~200-500ms**. If gaps are >1 second, it feels like a walkie-talkie or a bad long-distance call.
Standard AI (ChatGPT) takes 2-3 seconds to generate text. Adding Transcribing (STT) and Speaking (TTS) adds more time.

**The Traditional (Slow) Pipeline:**
1.  **VAD (Voice Activity Detection)**: "Did user stop talking?" (Wait 700ms silence)
2.  **STT (Speech-to-Text)**: Convert audio to text. (500ms)
3.  **LLM (Brain)**: Generate text response. (1000ms+)
4.  **TTS (Text-to-Speech)**: Generate audio. (500ms)
5.  **Network**: Send audio back. (100ms)
**Total**: ~3+ seconds. (Too slow!)

**The Vigilante (Fast) Pipeline:**
We use **Streaming & Speculative Execution**:
1.  **VAD**: Tuned to 200ms.
2.  **Streaming STT (Deepgram)**: Sends text *as the user speaks*.
3.  **Fast LLM (Groq)**: Generates the first token in <100ms.
4.  **Streaming TTS (Cartesia/Deepgram)**: Starts speaking *before the sentence is finished*.
**Total**: ~500-800ms. (Human-like!)

## 3. Architecture & Tech Stack

### The "Agentic Bus": LiveKit
We don't just glue APIs together; we use **LiveKit** as a real-time transport bus using WebRTC.
*   **Why WebRTC?** It's UDP-based (fire-and-forget), avoiding TCP handshake delays.
*   **Why LiveKit?** It handles the "Barge-In" logic (stopping the AI when the user interrupts) automatically.

### The Components
1.  **The Ear (STT)**: **Deepgram Nova-2**.
    *   *Why?* It's the fastest STT on the market (~300ms).
2.  **The Brain (LLM)**: **Llama 3.1 70B on Groq**.
    *   *Why?* Groq's LPU (Language Processing Unit) runs inference at 1000 tokens/sec. It's instant.
3.  **The Voice (TTS)**: **Deepgram Aura** or **Cartesia**.
    *   *Why?* Low latency TTS designed for voice agents.

## 4. Comparison: Why this stack?

| Feature | Standard (OpenAI API) | Vigilante Stack (LiveKit+Groq) |
| :--- | :--- | :--- |
| **Transport** | Rest API (HTTP) | WebRTC (UDP) |
| **Latency** | 3-5 seconds | 0.5 - 0.8 seconds |
| **Interruption** | Impossible (Talking over each other) | **Barge-In Supported** (AI stops instantly) |
| **Cost** | High (GPT-4) | Low (Llama 3 on Groq is cheap) |
| **Vibe** | Robotic Assistant | "Confused Grandma" |

## 5. Implementation Guide (Phase 3)

### Step 1: Directory Structure
Since you are working independently on Phase 3, create this structure:
```
/Phase3_Voice
  /agent
    agent.py            # The Main Brain
    personas.py         # "Grandma" and "Student" Prompts
  /frontend_demo        # Simple HTML/React file to test in browser
  requirements.txt
  .env                  # API KEYS (LiveKit, Groq, Deepgram)
```

### Step 2: The Environment (.env)
You will need these keys (all have free tiers):
```bash
LIVEKIT_URL=...
LIVEKIT_API_KEY=...
LIVEKIT_API_SECRET=...
DEEPGRAM_API_KEY=...
GROQ_API_KEY=...
```

### Step 3: Coding the Agent (`agent.py`)
We use the `livekit-agents` library.

```python
import asyncio
from livekit.agents import AutoSubscribe, JobContext, WorkerOptions, cli, llm
from livekit.plugins import deepgram, groq, silero

async def entrypoint(ctx: JobContext):
    # 1. Connect to the room
    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)

    # 2. Define the Agent
    agent = VoicePipelineAgent(
        vad=silero.VAD.load(),
        stt=deepgram.STT(),
        llm=groq.LLM(model="llama3-70b-8192"),
        tts=deepgram.TTS(),
        system_prompt="You are an elderly woman named Mrs. Sharma. You are confused by technology. You speak slowly."
    )

    # 3. Start the Agent
    agent.start(ctx.room)

    # 4. Say Hello
    await agent.say("Hello? Is this... is this the bank person?", allow_interruptions=True)

if __name__ == "__main__":
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))
```

### Step 4: Connecting the Phone (Twilio)
To make it a "HoneyPot", we connect a phone number.
1.  Buy a Twilio Number ($1).
2.  Set up **Twilio SIP Trunk** pointing to LiveKit SIP URI.
3.  When Scammer calls (+1-555-0199) -> Twilio -> SIP -> Vigilante Agent.

## 6. FAQ: Mobile & Costs

### Q1: Can I use this on my real mobile number?
**The Challenge**: Android/iOS **block apps** from recording regular phone calls for privacy. You cannot build an app that "listens" to your normal GSM calls in the background.

**The Solution (How we implement it)**:
1.  **Method A (The "Conference" Hack)**:
    *   Scammer calls your phone.
    *   You tap "Add Call" and dial your **Vigilante AI Number** (Twilio).
    *   You merge the calls. Now the AI is in the conference.
    *   You mute yourself. The AI talks to the scammer.
2.  **Method B (VoIP App)**:
    *   You give the scammer your **Vigilante App Number** (not your SIM number).
    *   The call rings *inside your app* (like WhatsApp).
    *   You answer in-app. The AI listens silently.
    *   **"Take Over" Button**: You press "Activate AI" -> The AI starts talking.

### Q2: Is this free?
For a Hackathon, **YES** (using Free Tiers). For Production, **NO**.

| Service | Free Tier | Hackathon Strategy |
| :--- | :--- | :--- |
| **LiveKit** | 50GB Bandwidth / mo | **Free** (More than enough) |
| **Deepgram (STT)** | $200 Free Credit | **Free** (Thousands of hours) |
| **Groq (LLM)** | Limited Free Beta | **Free** (Fast & Sufficient) |
| **Cartesia (TTS)** | Trial Credits | **Free** (Good for demos) |
| **Twilio** | $15 Trial Credit | **Free** (Buy 1 number for $1) |

**Verdict**: You can build and demo this for **$0** using trial accounts.

## 7. Report for Documentation
**Title**: Low-Latency Voice Agent Architecture for Scam Detection
**Abstract**: This system utilizes a WebSocket-based, full-duplex audio pipeline to simulate human interaction with high fidelity. By leveraging Groq's LPU inference engine and Deepgram's streaming transcription, we achieve an end-to-end conversational latency of <800ms, effectively passing the "Turing Test" for unsuspecting scammers.

## 8. Zero to Hero: How to Get Your API Keys

Since you are a beginner, here is the exact click-by-click guide to getting the keys you need.

### 1. LiveKit (The Backbone)
*   **What it does**: Handles the real-time audio connection.
*   **Where to go**: [livekit.io](https://livekit.io/) -> Click "Start for Free" (Cloud).
*   **Steps**:
    1.  Sign up with GitHub/Google.
    2.  Create a new "Project" (name it `vigilante`).
    3.  Go to **Settings** -> **Keys**.
    4.  Click **"Add Key"**.
    5.  Copy `API Key` and `Secret Key`.
    6.  **Save to `.env`**: `LIVEKIT_API_KEY` and `LIVEKIT_API_SECRET`.
    7.  Copy the `WebSocket URL` from the dashboard header (starts with `wss://`). **Save as** `LIVEKIT_URL`.

### 2. Deepgram (The Ear & Voice)
*   **What it does**: Super fast Speech-to-Text (STT) and Text-to-Speech (TTS).
*   **Where to go**: [console.deepgram.com](https://console.deepgram.com/signup)
*   **Steps**:
    1.  Sign up (Free $200 credit).
    2.  Go to **API Keys** -> **Create New**.
    3.  Select "Member" permissions (default).
    4.  Copy the key (starts with `nice...` or similar).
    5.  **Save to `.env`**: `DEEPGRAM_API_KEY`.

### 3. Groq (The Fast Brain)
*   **What it does**: Runs Llama 3 AI instantly.
*   **Where to go**: [console.groq.com](https://console.groq.com/)
*   **Steps**:
    1.  Login.
    2.  Go to **API Keys**.
    3.  Click **Create API Key**.
    4.  Copy it (starts with `gsk_...`).
    5.  **Save to `.env`**: `GROQ_API_KEY`.

### 4. Cartesia (The Realistic Voice - Optional)
*   **What it does**: Makes the voice sound hyper-realistic (better than Deepgram).
*   **Where to go**: [cartesia.ai](https://cartesia.ai/)
*   **Steps**:
    1.  Get access (they have a trial).
    2.  Create API Key.
    3.  **Save to `.env`**: `CARTESIA_API_KEY`.
    *   *Note*: If this is too hard, skip it and use **Deepgram Aura** (included in step 2).

### 5. Twilio (The Phone Line)
*   **What it does**: Gives you a real phone number (+1-555...).
*   **In your screenshot**: You asked "Which one to choose?" -> **Choose "Voice"**.
*   **Steps**:
    1.  Go to [twilio.com](https://twilio.com) -> Start for Free.
    2.  Verify your own phone number (Sandbox requirement).
    3.  Basic Dashboard: Click **"Get a Trial Number"**.
    4.  You will get a number like `+1 555 123 4567`.
    5.  Scroll down to **Account Info**.
    6.  Copy `Account SID` and `Auth Token`.
    7.  **Save to `.env`**: `TWILIO_ACCOUNT_SID` and `TWILIO_AUTH_TOKEN`.
    *   *Note*: To connect this number to LiveKit, you will eventually use "SIP Trunking", but start by just getting the number in the "Voice" section.
